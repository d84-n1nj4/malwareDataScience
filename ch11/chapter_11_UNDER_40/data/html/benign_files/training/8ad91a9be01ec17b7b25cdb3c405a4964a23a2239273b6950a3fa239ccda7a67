<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <title>tHDFSRename</title><link rel="stylesheet" type="text/css" href="../css/talend_components_eclipse.css"><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"><meta name="keywords" content="hadoop_hdfs, thdfsrename"><link rel="home" href="bk-components-rg-en..html" title="Talend Components"><link rel="up" href="ch-bigdata.html" title="Chapter&nbsp;1.&nbsp;Big Data components"><link rel="prev" href="tHDFSPut.html" title="tHDFSPut"><link rel="next" href="tHDFSRowCount.html" title="tHDFSRowCount"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">tHDFSRename</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="tHDFSPut.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;1.&nbsp;Big Data components</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="tHDFSRowCount.html">Next</a></td></tr></table><hr></div><div lang="en" class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="tHDFSRename"></a>tHDFSRename</h2></div></div></div><div class="mediaobject"><img src="../images/tHDFSRename_icon32_white.png"></div><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>This component will be available in the <span class="emphasis"><strong>Palette</strong></span> of
				<span class="emphasis"><em>Talend Studio</em></span> on the condition that you have subscribed to one of
			the <span class="emphasis"><strong>Talend</strong></span>
			solutions with Big Data.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e36651"></a>tHDFSRename Properties</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col class="c1"><col class="c2"><col class="c3"></colgroup><tbody><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Component Family</strong></span>
							</p>
						</td><td valign="top">
							<p>Big Data/HDFS</p>
						</td><td valign="top">&nbsp;</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Function</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tHDFSRename</strong></span> renames the selected
								files or specified directory on HDFS.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Purpose</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tHDFSRename</strong></span> renames files
								selected from a local directory towards a distant HDFS
								directory.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Basic settings</strong></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Property type</em></span>
							</p>
						</td><td valign="top">
							<p>Either <span class="emphasis"><strong>Built-in</strong></span> or <span class="emphasis"><strong>Repository</strong></span></p>
							<p>
								<span class="emphasis"><strong>Built-in</strong></span>: No property data stored
								centrally.</p>
							<p>
								<span class="emphasis"><strong>Repository</strong></span>: Select the repository
								file in which the properties are stored. The fields that follow are
								completed automatically using the data retrieved.</p>
							<p>Since version 5.6, both the Built-In mode and the Repository mode are
		available in any of the <span class="emphasis"><em>Talend</em></span> solutions.</p>
						</td></tr><tr><td>
							<p>&nbsp; </p>
						</td><td valign="top">
							<p>
		<span class="emphasis"><em>Use an existing connection</em></span>
	</p>
						</td><td valign="top">
							<p>Select this check box and in the <span class="emphasis"><strong>Component List</strong></span> click the
		relevant connection component to reuse the connection details you already defined.</p>
							<p> </p>
							<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>When a Job contains the parent Job and the child Job, <span class="emphasis"><strong>Component
				list</strong></span> presents only the connection components in the same Job
			level.</p></div>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><em>Version</em></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Distribution</em></span>
							</p>
						</td><td valign="top">
							<p>Select the cluster you are using from the drop-down list. The options in the list vary
		depending on the component you are using. Among these options, the following ones requires
		specific configuration:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>If available in this <span class="emphasis"><strong>Distribution</strong></span> drop-down list, the
                <span class="emphasis"><strong>Microsoft HD Insight</strong></span> option allows you to use a
                Microsoft HD Insight cluster. For this purpose, you need to configure the
                connections to the WebHCat service, the HD Insight service and the Windows Azure
                Storage service of that cluster in the areas that are displayed.  A demonstration
                video about how to configure this connection is available in the following link:
                <a class="link" href="https://www.youtube.com/watch?v=A3QTT6VsNoM" target="_top">https://www.youtube.com/watch?v=A3QTT6VsNoM</a></p></li><li class="listitem"><p>The <span class="emphasis"><strong>Custom</strong></span> option allows you to connect to a
					cluster different from any of the distributions given in this list, that is to
					say, to connect to a cluster not officially supported by <span class="emphasis"><strong>Talend</strong></span>.</p></li></ul></div>
							<div class="orderedlist"><p>In order to connect to a custom distribution, once selecting <span class="emphasis"><strong>Custom</strong></span>, click the <span class="inlinemediaobject"><img src="../images/dotbutton.png"></span> button to display the dialog box in which you can
			alternatively:</p><ol class="orderedlist" type="1"><li class="listitem"><p>Select <span class="emphasis"><strong>Import from existing version</strong></span> to import an
				officially supported distribution as base and then add other required jar files
				which the base distribution does not provide.</p></li><li class="listitem"><p>Select <span class="emphasis"><strong>Import from zip</strong></span> to import a custom
				distribution zip that, for example, you can download from <a class="link" href="http://www.talendforge.org/exchange/index.php" target="_top">http://www.talendforge.org/exchange/index.php</a>.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>In this dialog box, the active check box must be kept selected so as to import
					the jar files pertinent to the connection to be created between the custom
					distribution and this component.</p></div><p>For an step-by-step example about how to connect to a custom distribution and
				share this connection, see <a class="xref" href="tHiveConnection.html#ychen-20130408-big_data-custom_hadoop" title="Connecting to a custom Hadoop distribution"><i>Connecting to a custom Hadoop distribution</i></a>.</p></li></ol></div>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Hadoop version</em></span>
							</p>
						</td><td valign="top">
							<p>Select the version of the Hadoop distribution you are using. The available options vary
        depending on the component you are using. Along with the evolution of Hadoop, please note
        the following changes: </p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>If you use <span class="emphasis"><strong>Hortonworks Data Platform V2.2</strong></span>, the
                configuration files of your cluster might be using environment variables such as
                <span class="emphasis"><em>${hdp.version}</em></span>. If this is your situation, you
                need to set the <span class="emphasis"><em>mapreduce.application.framework.path</em></span> property in the <span class="emphasis"><strong>Hadoop properties</strong></span> table of this component with the path value
                explicitly pointing to the MapReduce framework archive of your cluster. For
                example:</p><pre class="programlisting">mapreduce.application.framework.path=/hdp/apps/2.2.0.0-2041/mapreduce/mapreduce.tar.gz#mr-framework</pre></li><li class="listitem"><p>If you use <span class="emphasis"><strong>Hortonworks Data Platform V2.0.0</strong></span>, the
                type of the operating system for running the distribution and a <span class="emphasis"><strong>Talend</strong></span>
                Job must be the same, such as Windows or Linux. Otherwise, you have to use <span class="emphasis"><strong>Talend</strong></span>
                Jobserver to execute the Job in the same type of operating system in which the
                <span class="emphasis"><strong>Hortonworks Data Platform V2.0.0</strong></span> distribution you
                are using is run. For further information about <span class="emphasis"><strong>Talend</strong></span> Jobserver, see
                <span class="emphasis"><em>Talend Installation
                and Upgrade Guide</em></span>.</p></li></ul></div>
						</td></tr><tr><td>
							<p>&nbsp;<span class="emphasis"><em>Authentication</em></span></p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Use kerberos authentication</em></span>
							</p>
						</td><td valign="top">
							<p>If you are accessing the Hadoop cluster running with Kerberos security, select this check
		box, then, enter the Kerberos principal name for the NameNode in the field displayed. This
		enables you to use your user name to authenticate against the credentials stored in
		Kerberos.</p>
							<p>This check box is available depending on the Hadoop distribution you are connecting
		to.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<span class="emphasis"><em>Use a keytab to authenticate</em></span>
						</td><td valign="top">
							<p>Select the <span class="emphasis"><strong>Use a keytab to authenticate</strong></span> check box to log
		into a Kerberos-enabled Hadoop system using a given keytab file. A keytab file contains
		pairs of Kerberos principals and encrypted keys. You need to enter the principal to be used
		in the <span class="emphasis"><strong>Principal</strong></span> field and the access path to the keytab
		file itself in the <span class="emphasis"><strong>Keytab</strong></span> field. </p>
							<p>Note that the user that executes a keytab-enabled Job is not necessarily the one a
		principal designates but must have the right to read the keytab file being used. For
		example, the user name you are using to execute a Job is <span class="emphasis"><em>user1</em></span> and the principal to be used is <span class="emphasis"><em>guest</em></span>; in this situation, ensure that <span class="emphasis"><em>user1</em></span> has the right to read the keytab file to be used.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>NameNode URI</em></span>
							</p>
						</td><td valign="top">
							<p>Type in the URI of the Hadoop NameNode. The NameNode is the master node of a Hadoop system.
		For example, we assume that you have chosen a machine called <span class="emphasis"><em>masternode</em></span> as the NameNode of an Apache Hadoop distribution, then the
		location is <span class="emphasis"><em>hdfs://masternode:portnumber</em></span>.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>User name</em></span>
							</p>
						</td><td>
							<p>Enter the user authentication name of HDFS.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Group</em></span>
							</p>
						</td><td valign="top">
							<p>Enter the membership including the authentication user under which the HDFS instances were
		started. This field is available depending on the distribution you are using.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>HDFS directory</em></span>
							</p>
						</td><td valign="top">
							<p>Browse to, or enter the directory in HDFS where the data you need to use is.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Overwrite file</em></span>
							</p>
						</td><td valign="top">
							<p>Select the options to overwrite or not the existing file with the
								new one.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Files</em></span>
							</p>
						</td><td valign="top">
							<p>Click the <span class="emphasis"><strong>[+]</strong></span> button to add the
								lines you want to use as filters:</p>
							<p>
								<span class="emphasis"><strong>Filemask</strong></span>: enter the filename or
								filemask using wildcharacters (*) or regular expressions.</p>
							<p>
								<span class="emphasis"><strong>New name</strong></span>: name to give to the HDFS
								file after the transfer.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Die on error</em></span>
							</p>
						</td><td valign="top">
							<p>This check box is selected by default. Clear the check box to skip
								the row in error and complete the process for error-free
								rows.</p>
						</td></tr><tr><td>
							<p>
								<span class="emphasis"><strong>Advanced settings</strong></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>tStatCatcher Statistics</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to gather the Job processing metadata at a
								Job level as well as at each component level.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Hadoop properties</em></span>
							</p>
						</td><td valign="top">
							<p><span class="emphasis"><em>Talend Studio</em></span> uses a default configuration for its engine to perform
		operations in a Hadoop distribution. If you need to use a custom configuration in a specific
		situation, complete this table with the property or properties to be customized. Then at
		runtime, the customized property or properties will override those default ones. </p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Note that if you are using the centrally stored metadata from the <span class="emphasis"><strong>Repository</strong></span>, this table automatically inherits the
					properties defined in that metadata and becomes uneditable unless you change the
						<span class="emphasis"><strong>Property type</strong></span> from <span class="emphasis"><strong>Repository</strong></span> to <span class="emphasis"><strong>Built-in</strong></span>.</p></li></ul></div>
							<p>For further information about the properties required by Hadoop and its related systems such
	    as HDFS and Hive, see the documentation of the Hadoop distribution you
	    are using or see Apache's Hadoop documentation on <a class="link" href="http://hadoop.apache.org/docs" target="_top">http://hadoop.apache.org/docs</a> and then select the version of the documentation you want. For demonstration purposes, the links to some properties are listed below:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Typically, the HDFS-related properties can be found in the <span class="emphasis"><em>hdfs-default.xml</em></span> file of your distribution, such as
						<a class="link" href="http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_top">
						http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a>.</p></li><li class="listitem"><p>Apache also provides a page to list the Hive-related properties: <a class="link" href="https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties" target="_top">https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties</a>.</p></li></ul></div>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Dynamic settings</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>Click the <span class="emphasis"><strong>[+]</strong></span> button to add a row in the table and fill the
			<span class="emphasis"><strong>Code</strong></span> field with a context variable to choose your HDFS
		connection dynamically from multiple connections planned in your Job. This feature is useful
		when you need to access files in different HDFS systems or different distributions,
		especially when you are working in an environment where you cannot change your Job settings,
		for example, when your Job has to be deployed and executed independent of <span class="emphasis"><em>Talend Studio</em></span>.</p>
							<p>The <span class="emphasis"><strong>Dynamic settings</strong></span> table is available only when the
			<span class="emphasis"><strong>Use an existing connection</strong></span> check box is selected in the
			<span class="emphasis"><strong>Basic settings</strong></span> view. Once a dynamic parameter is
		defined, the <span class="emphasis"><strong>Component List</strong></span> box in the <span class="emphasis"><strong>Basic settings</strong></span> view becomes unusable. </p>
							<p>For more information on <span class="emphasis"><strong>Dynamic settings</strong></span> and context
		variables, see <span class="emphasis"><em>Talend Studio User Guide</em></span>.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Global Variables</strong></span>
							</p>
						</td><td colspan="2">
							<p>
		<span class="emphasis"><strong>NB_FILE</strong></span>: the number of files processed. This is an After
		variable and it returns an integer. </p>
							<p><span class="emphasis"><strong>CURRENT_STATUS</strong></span>: the execution result of the component.
		This is a Flow variable and it returns a string.</p>
							<p><span class="emphasis"><strong>ERROR_MESSAGE</strong></span>: the error message generated by the
		component when an error occurs. This is an After variable and it returns a string. This
		variable functions only if the <span class="emphasis"><strong>Die on error</strong></span> check box is
		cleared, if the component has this check box.</p>
							<p>A Flow variable functions during the execution of a component while an After variable
		functions after the execution of the component.</p>
							<p>To fill up a field or expression with a variable, press <span class="emphasis"><strong>Ctrl +
			Space</strong></span> to access the variable list and choose the variable to use from it. </p>
							<p> For further information about variables, see <span class="emphasis"><em>Talend Studio</em></span>
		<span class="emphasis"><em>User Guide</em></span>.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Usage</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>This component is used to compose a single-component Job or
								Subjob.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Prerequisites</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>The Hadoop distribution must be properly installed, so as to guarantee the interaction
		with <span class="emphasis"><em>Talend Studio</em></span>. The following list presents MapR related information for
		example.</p>
							<div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Ensure that you have installed the MapR client in the machine where the Studio is,
				and added the MapR client library to the PATH variable of that machine.  According
				to MapR's documentation, the library or libraries of a MapR client corresponding to
				each OS version can be found under <span class="emphasis"><em>MAPR_INSTALL\
					hadoop\hadoop-VERSION\lib\native</em></span>. For example, the library for
				Windows is <span class="emphasis"><em>\lib\native\MapRClient.dll</em></span> in the MapR
				client jar file. For further information, see the following link from MapR: <a class="link" href="http://www.mapr.com/blog/basic-notes-on-configuring-eclipse-as-a-hadoop-development-environment-for-mapr" target="_top">http://www.mapr.com/blog/basic-notes-on-configuring-eclipse-as-a-hadoop-development-environment-for-mapr</a>.</p><p>Without adding the specified library or libraries, you may encounter the following
				error: <code class="code">no MapRClient in java.library.path</code>.</p></li><li class="listitem"><p>Set the <code class="code">-Djava.library.path</code> argument, for example, in the <span class="emphasis"><strong>Job Run VM arguments</strong></span> area
				of the <span class="emphasis"><strong>Run/Debug</strong></span> view in the <span class="emphasis"><strong>[Preferences]</strong></span> dialog box. This argument provides to the Studio the
				path to the native library of that MapR client. This allows the subscription-based
				users to make full use of the <span class="emphasis"><strong>Data viewer</strong></span> to view
				locally in the Studio the data stored in MapR. For further information about how to
				set this argument, see the section describing how to view data of <span class="emphasis"><em>Talend Big Data Getting Started Guide</em></span>.</p></li></ul></div>
							<p>For further information about how to install a Hadoop distribution, see the manuals
		corresponding to the Hadoop distribution you are using.</p>
						</td></tr><tr><td valign="top"><p><span class="emphasis"><strong>Log4j</strong></span></p></td><td colspan="2" valign="top"><p>The activity of this component can be logged using the <span class="emphasis"><em>log4j</em></span> feature. For more information on this feature, see <span class="emphasis"><em>Talend Studio User
        Guide</em></span>.</p><p>For more information on the log4j logging levels, see the Apache documentation at <a class="link" href="http://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/Level.html" target="_top">http://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/Level.html</a>.</p></td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Limitation</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>JRE 1.6+ is required.</p>
						</td></tr></tbody></table></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e37403"></a>Related scenario</h3></div></div></div><p>For related scenario, see <a class="xref" href="tHDFSGet.html#Raa73387" title="Scenario: Computing data with Hadoop distributed file system"><i>Scenario: Computing data with Hadoop distributed file system</i></a>.</p></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="tHDFSPut.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="ch-bigdata.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="tHDFSRowCount.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">tHDFSPut&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="bk-components-rg-en..html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;tHDFSRowCount</td></tr></table></div></body></html>